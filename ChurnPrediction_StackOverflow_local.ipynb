{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paper: https://www.andrew.cmu.edu/user/lakoglu/pubs/StackOverflow-churn.pdf\n",
    "\n",
    "Description of datasets: https://ia800107.us.archive.org/27/items/stackexchange/readme.txt\n",
    "\n",
    "Site for download of datasets: https://archive.org/details/stackexchange\n",
    "\n",
    "This code has 6 steps\n",
    "\n",
    "    1. Load StackOverflow datasets as dataframe\n",
    "    2. Extract and label the datasets for each task\n",
    "    3. Extract features for each task\n",
    "    4. Analyze features|\n",
    "    5. Train models for each task with the features\n",
    "    6. Quantify the importance of each feature category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load StackOverflow datasets as dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xmltodict in c:\\programdata\\anaconda3\\lib\\site-packages (0.12.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip --proxy http://10.241.3.7:8080 install xmltodict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xmltodict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_dir = 'stackoverflow.com/'  ### Full dataset\n",
    "xml_dir = 'math.stackexchange.com/'   ### Small dataset\n",
    "xml_dir = 'academia.meta.stackexchange.com/'   ### Tiny dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read xml file and transform to pandas dataframe\n",
    "\n",
    "import json\n",
    "\n",
    "def xml2df(xml_path):\n",
    "    f = open(xml_path, 'r', encoding='UTF8')\n",
    "    data = f.read()\n",
    "    f.close()\n",
    "    xml_dict = xmltodict.parse(data)\n",
    "    key = list(xml_dict.keys())[0]\n",
    "    df = pd.DataFrame(xml_dict[key]['row'])\n",
    "    df.columns = [col.replace('@', '') for col in df.columns]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'[-1] not found in axis'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-467-0db68c6fb751>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0musers_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mReputation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0musers_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mReputation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'int64'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0musers_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0musers_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Id'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0musers_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0musers_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0musers_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4100\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4101\u001b[0m             \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4102\u001b[1;33m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4103\u001b[0m         )\n\u001b[0;32m   4104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3912\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3913\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3914\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3916\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   3944\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3945\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3946\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3947\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3948\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   5338\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5339\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5340\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{} not found in axis\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5341\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5342\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '[-1] not found in axis'"
     ]
    }
   ],
   "source": [
    "# 1. Read Users.xml\n",
    "xml_path = xml_dir + 'Users.xml'\n",
    "users_df = xml2df(xml_path)\n",
    "\n",
    "# 2. Change data type of columns\n",
    "users_df = users_df[['Id', 'Reputation', 'CreationDate', 'LastAccessDate']]\n",
    "users_df.CreationDate = pd.to_datetime(users_df.CreationDate)\n",
    "users_df.LastAccessDate = pd.to_datetime(users_df.LastAccessDate)\n",
    "users_df.Id = users_df['Id'].astype('int64')\n",
    "users_df.Reputation = users_df.Reputation.astype('int64')\n",
    "users_df = users_df.set_index('Id')\n",
    "users_df = users_df.drop([-1])\n",
    "\n",
    "print(users_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                CreationDate AcceptedAnswerId Score  OwnerUserId\n",
      "Id                                                              \n",
      "1    2012-02-14 20:39:10.140              NaN     4            5\n",
      "2    2012-02-14 20:41:04.273              NaN     3            5\n",
      "4    2012-02-14 21:37:15.053                5     3           30\n",
      "5    2012-02-14 21:46:33.213              NaN     5           23\n",
      "6    2012-02-14 22:07:56.987              NaN     4           31\n",
      "...                      ...              ...   ...          ...\n",
      "4526 2019-08-21 05:58:07.673              NaN    15          118\n",
      "4527 2019-08-21 06:07:55.123              NaN     7        13240\n",
      "4528 2019-08-26 01:57:43.213              NaN     3        21968\n",
      "4529 2019-08-26 06:06:01.747              NaN     1         7734\n",
      "4530 2019-08-27 16:06:35.500              NaN     4           73\n",
      "\n",
      "[3068 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# 1. Read Posts.xml\n",
    "xml_path = xml_dir + 'Posts.xml'\n",
    "posts_df = xml2df(xml_path)\n",
    "\n",
    "# 2. Change data type of columns\n",
    "posts_df = posts_df[['Id', 'CreationDate', 'AcceptedAnswerId', 'Score', 'OwnerUserId']]\n",
    "posts_df.CreationDate = pd.to_datetime(posts_df.CreationDate)\n",
    "posts_df.Id = posts_df.Id.astype('int64')\n",
    "posts_df = posts_df.dropna(subset=['OwnerUserId'])\n",
    "posts_df.OwnerUserId = posts_df.OwnerUserId.astype('int64')\n",
    "posts_df = posts_df.set_index('Id')\n",
    "print(posts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and Load dataframe\n",
    "\n",
    "def save_df(df, filename):\n",
    "    df.to_pickle(\"{}.pkl\".format(filename))\n",
    "\n",
    "    \n",
    "def load_df(filename):\n",
    "    return pd.read_pickle(\"{}.pkl\".format(filename))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Extract and label the datasets for each task\n",
    "\n",
    "You should extract the dataset for the period of the dataset: July 31, 2008 ~  July 31, 2012 \n",
    "\n",
    "There are 2 tasks:\n",
    "\n",
    "    A. After a user's K-th post, predict how likely it is that the user will churn\n",
    "    B. After the T-th day from the account creation of a user, predict how likely it is that the user will churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               CreationDate AcceptedAnswerId Score  OwnerUserId\n",
      "Id                                                             \n",
      "1   2012-02-14 20:39:10.140              NaN     4            5\n",
      "2   2012-02-14 20:41:04.273              NaN     3            5\n",
      "4   2012-02-14 21:37:15.053                5     3           30\n",
      "5   2012-02-14 21:46:33.213              NaN     5           23\n",
      "6   2012-02-14 22:07:56.987              NaN     4           31\n",
      "..                      ...              ...   ...          ...\n",
      "155 2012-07-08 17:35:27.660              NaN     1           65\n",
      "156 2012-07-14 08:48:00.980              NaN     5           81\n",
      "157 2012-07-23 07:33:01.473              160    10          929\n",
      "159 2012-07-23 16:56:29.283              NaN     5         1033\n",
      "160 2012-07-23 21:43:41.267              NaN    11          346\n",
      "\n",
      "[132 rows x 4 columns]\n",
      "      Reputation        CreationDate          LastAccessDate\n",
      "Id                                                          \n",
      "2            101 2012-02-14 20:17:36 2014-08-29 13:45:59.997\n",
      "3           3114 2012-02-14 20:20:16 2017-10-28 00:57:06.677\n",
      "5           1969 2012-02-14 20:22:08 2014-05-24 05:16:16.957\n",
      "6            445 2012-02-14 20:22:35 2012-02-20 19:25:09.473\n",
      "7            101 2012-02-14 20:22:57 2016-04-30 16:41:24.893\n",
      "...          ...                 ...                     ...\n",
      "1374         101 2012-07-28 00:26:21 2019-01-15 16:05:55.030\n",
      "1375         201 2012-07-28 07:42:36 2017-02-11 04:44:23.323\n",
      "1380         219 2012-07-28 21:17:56 2015-12-26 16:59:12.450\n",
      "1382         101 2012-07-29 06:04:17 2016-01-12 22:13:46.757\n",
      "1384         101 2012-07-29 19:31:49 2018-05-01 21:32:14.483\n",
      "\n",
      "[423 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# You should extract the dataset for the period of the dataset: July 31, 2008 ~  July 31, 2012\n",
    "\n",
    "start_time = pd.to_datetime('2008-07-31')\n",
    "end_time = pd.to_datetime('2012-07-31')\n",
    "\n",
    "posts_df = posts_df[(posts_df['CreationDate'] >= start_time) & (posts_df['CreationDate'] <= end_time)]\n",
    "users_df = users_df[(users_df['CreationDate'] >= start_time) & (users_df['CreationDate'] <= end_time)]\n",
    "\n",
    "print(posts_df)\n",
    "print(users_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   OwnerUserId            CreationDate AcceptedAnswerId Score\n",
      "0            5 2012-02-16 01:25:12.627              NaN     3\n",
      "1           23 2012-05-24 20:47:38.473              NaN     1\n",
      "2           53 2012-03-07 21:38:42.657              NaN     7\n",
      "3           73 2012-02-21 20:04:30.667               38     4\n",
      "4           96 2012-03-07 05:03:26.243              NaN     2\n",
      "    Reputation        CreationDate          LastAccessDate\n",
      "Id                                                        \n",
      "5         1969 2012-02-14 20:22:08 2014-05-24 05:16:16.957\n",
      "23         101 2012-02-14 20:33:51 2019-01-31 21:34:44.323\n",
      "53      162384 2012-02-14 21:47:58 2019-02-08 21:12:16.727\n",
      "73       42744 2012-02-15 00:04:47 2019-08-28 17:51:31.323\n",
      "96       24181 2012-02-15 11:27:39 2018-08-27 15:03:34.713\n"
     ]
    }
   ],
   "source": [
    "# Dataset in Task 1\n",
    "#   Posts: Extract K posts of each user\n",
    "#   Users: Extract users who post at least K\n",
    "\n",
    "def getTask1Posts(posts, K=20):\n",
    "    group_posts = posts.groupby('OwnerUserId')\n",
    "    kth_group_posts = group_posts.nth(K)\n",
    "    return kth_group_posts.reset_index()\n",
    "\n",
    "def getTask1Users(users, posts, K=20):\n",
    "    kth_posts = getTask1Posts(posts, K)\n",
    "    return users[users.index.isin(kth_posts.OwnerUserId)]\n",
    "\n",
    "ex1 = getTask1Posts(posts_df, K=5)\n",
    "print(ex1)\n",
    "\n",
    "ex2 = getTask1Users(users_df, posts_df, K=5)\n",
    "print(ex2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               CreationDate AcceptedAnswerId Score  OwnerUserId  \\\n",
      "Id                                                                \n",
      "1   2012-02-14 20:39:10.140              NaN     4            5   \n",
      "2   2012-02-14 20:41:04.273              NaN     3            5   \n",
      "5   2012-02-14 21:46:33.213              NaN     5           23   \n",
      "6   2012-02-14 22:07:56.987              NaN     4           31   \n",
      "7   2012-02-14 22:11:59.587               26     9           31   \n",
      "..                      ...              ...   ...          ...   \n",
      "151 2012-06-27 19:01:47.187              NaN     4           53   \n",
      "152 2012-07-04 05:07:45.260              154     5          411   \n",
      "153 2012-07-04 12:49:41.820              NaN     6          929   \n",
      "157 2012-07-23 07:33:01.473              160    10          929   \n",
      "160 2012-07-23 21:43:41.267              NaN    11          346   \n",
      "\n",
      "       UserCreationDate  DiffCreationDate  \n",
      "Id                                         \n",
      "1   2012-02-14 20:22:08                 0  \n",
      "2   2012-02-14 20:22:08                 0  \n",
      "5   2012-02-14 20:33:51                 0  \n",
      "6   2012-02-14 20:46:45                 0  \n",
      "7   2012-02-14 20:46:45                 0  \n",
      "..                  ...               ...  \n",
      "151 2012-02-14 21:47:58               133  \n",
      "152 2012-03-14 08:27:22               111  \n",
      "153 2012-05-25 13:52:16                39  \n",
      "157 2012-05-25 13:52:16                58  \n",
      "160 2012-03-06 06:39:59               139  \n",
      "\n",
      "[106 rows x 6 columns]\n",
      "               CreationDate AcceptedAnswerId Score  OwnerUserId  \\\n",
      "Id                                                                \n",
      "1   2012-02-14 20:39:10.140              NaN     4            5   \n",
      "2   2012-02-14 20:41:04.273              NaN     3            5   \n",
      "5   2012-02-14 21:46:33.213              NaN     5           23   \n",
      "6   2012-02-14 22:07:56.987              NaN     4           31   \n",
      "7   2012-02-14 22:11:59.587               26     9           31   \n",
      "..                      ...              ...   ...          ...   \n",
      "84  2012-03-08 01:57:23.020              NaN     7           73   \n",
      "87  2012-03-11 04:52:00.050              NaN     8           73   \n",
      "88  2012-03-11 18:05:00.870              NaN     3           73   \n",
      "91  2012-03-16 17:58:39.993              NaN     6          346   \n",
      "146 2012-06-25 09:28:58.810              NaN     5          929   \n",
      "\n",
      "       UserCreationDate  DiffCreationDate  \n",
      "Id                                         \n",
      "1   2012-02-14 20:22:08                 0  \n",
      "2   2012-02-14 20:22:08                 0  \n",
      "5   2012-02-14 20:33:51                 0  \n",
      "6   2012-02-14 20:46:45                 0  \n",
      "7   2012-02-14 20:46:45                 0  \n",
      "..                  ...               ...  \n",
      "84  2012-02-15 00:04:47                22  \n",
      "87  2012-02-15 00:04:47                25  \n",
      "88  2012-02-15 00:04:47                25  \n",
      "91  2012-03-06 06:39:59                10  \n",
      "146 2012-05-25 13:52:16                30  \n",
      "\n",
      "[62 rows x 6 columns]\n",
      "               CreationDate AcceptedAnswerId Score  OwnerUserId  \\\n",
      "Id                                                                \n",
      "1   2012-02-14 20:39:10.140              NaN     4            5   \n",
      "2   2012-02-14 20:41:04.273              NaN     3            5   \n",
      "5   2012-02-14 21:46:33.213              NaN     5           23   \n",
      "6   2012-02-14 22:07:56.987              NaN     4           31   \n",
      "7   2012-02-14 22:11:59.587               26     9           31   \n",
      "..                      ...              ...   ...          ...   \n",
      "84  2012-03-08 01:57:23.020              NaN     7           73   \n",
      "87  2012-03-11 04:52:00.050              NaN     8           73   \n",
      "88  2012-03-11 18:05:00.870              NaN     3           73   \n",
      "91  2012-03-16 17:58:39.993              NaN     6          346   \n",
      "146 2012-06-25 09:28:58.810              NaN     5          929   \n",
      "\n",
      "       UserCreationDate  DiffCreationDate  \n",
      "Id                                         \n",
      "1   2012-02-14 20:22:08                 0  \n",
      "2   2012-02-14 20:22:08                 0  \n",
      "5   2012-02-14 20:33:51                 0  \n",
      "6   2012-02-14 20:46:45                 0  \n",
      "7   2012-02-14 20:46:45                 0  \n",
      "..                  ...               ...  \n",
      "84  2012-02-15 00:04:47                22  \n",
      "87  2012-02-15 00:04:47                25  \n",
      "88  2012-02-15 00:04:47                25  \n",
      "91  2012-03-06 06:39:59                10  \n",
      "146 2012-05-25 13:52:16                30  \n",
      "\n",
      "[62 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Dataset in Task 2\n",
    "#   Users: Extract users who post at least 1\n",
    "#   Posts: Extract posts which create before T day from the account creation of the owner\n",
    "\n",
    "def getTask2Posts(users, posts, T=30):\n",
    "    users = getTask1Users(users, posts, 1)\n",
    "    posts = posts[posts.OwnerUserId.isin(users.index)]\n",
    "    backup_index = posts.index\n",
    "\n",
    "    posts = posts.reset_index(drop=True)\n",
    "    posts['UserCreationDate'] = users.loc[posts.OwnerUserId, 'CreationDate'].reset_index(drop=True)\n",
    "    posts['DiffCreationDate'] = (posts.CreationDate - posts.UserCreationDate).dt.days\n",
    "    posts.index = backup_index\n",
    "    print(posts)\n",
    "    \n",
    "    posts = posts[posts.DiffCreationDate <= T]\n",
    "    print(posts)\n",
    "    #posts.drop(columns=['UserCreationDate', 'DiffCreationDate'])\n",
    "\n",
    "    return posts\n",
    "\n",
    "ex3 = getTask2Posts(users_df, posts_df, T=30)\n",
    "print(ex3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     is_churn\n",
      "@Id          \n",
      "5         0.0\n",
      "23        0.0\n",
      "53        0.0\n",
      "66        1.0\n",
      "73        0.0\n",
      "96        0.0\n",
      "118       0.0\n",
      "346       0.0\n"
     ]
    }
   ],
   "source": [
    "# Churn in Task 1\n",
    "#   Churners: Users who did not post for at least 6 months from their K-th post \n",
    "#   Stayers:  Users who created at least one post within the 6 months from their K-th post\n",
    "\n",
    "def getTask1Labels(users, posts, K=20):\n",
    "    label_df = getTask1Users(users, posts, K=K).set_index('@Id')\n",
    "    label_df = label_df.drop(label_df.columns, axis=1)\n",
    "    \n",
    "    posts_k = getTask1Posts(posts, K=K).set_index('@OwnerUserId')\n",
    "    posts_k_1 = getTask1Posts(posts, K=K + 1).set_index('@OwnerUserId')\n",
    "    diff = (posts_k_1.loc[posts_k.index, '@CreationDate'] - posts_k.loc[:, '@CreationDate']).fillna(pd.Timedelta(days=181))\n",
    "\n",
    "    label_df['is_churn'] = 0.0\n",
    "    label_df[diff.loc[label_df.index] > pd.Timedelta(days=180)] = 1.0\n",
    "    return label_df\n",
    "\n",
    "ex4 = getTask1Labels(users_df, posts_df, 3)\n",
    "print(ex4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              is_churn\n",
      "@OwnerUserId          \n",
      "100                1.0\n",
      "118                1.0\n",
      "201                1.0\n",
      "23                 0.0\n",
      "3                  1.0\n",
      "31                 1.0\n",
      "324                1.0\n",
      "346                0.0\n",
      "49                 0.0\n",
      "5                  1.0\n",
      "53                 0.0\n",
      "62                 0.0\n",
      "66                 1.0\n",
      "73                 0.0\n",
      "8                  1.0\n",
      "929                0.0\n",
      "96                 0.0\n"
     ]
    }
   ],
   "source": [
    "# Churn in Task2\n",
    "#   Churners: Users who did not post for at least 6 months from T days after account creation\n",
    "#   Stayers:  Users who created at least one post within the 6 months from T days after account creation\n",
    "\n",
    "def getTask2Labels(users, posts, T=30):\n",
    "    label_df = getTask1Users(users, posts, K=1).set_index('@Id')\n",
    "    label_df = label_df.drop(label_df.columns, axis=1)\n",
    "    \n",
    "    posts_t = getTask2Posts(users, posts, T=T)\n",
    "    posts_t_size = posts_t.groupby('@OwnerUserId').size()\n",
    "    label_df = posts_t_size.index\n",
    "    posts_t_180 = getTask2Posts(users, posts, T=T + 180)\n",
    "    posts_t_180_size = posts_t_180.groupby('@OwnerUserId').size()\n",
    "    new_posts_size = posts_t_180_size.loc[label_df] - posts_t_size[label_df]\n",
    "    \n",
    "    label_df = pd.DataFrame(index=label_df)\n",
    "    label_df['is_churn'] = 1.0\n",
    "    label_df[new_posts_size > 0] = 0.0\n",
    "\n",
    "    return label_df\n",
    "\n",
    "ex5 = getTask2Labels(users_df, posts_df, T=30)\n",
    "print(ex5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Extract features for each task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-1. Temporal features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@Id\n",
      "3       6 days 02:42:51.487000\n",
      "5       0 days 00:18:56.273000\n",
      "8       1 days 17:32:21.850000\n",
      "23     12 days 03:52:03.527000\n",
      "31      0 days 01:25:14.587000\n",
      "49     10 days 03:11:47.340000\n",
      "53      6 days 22:36:11.110000\n",
      "62     97 days 13:16:38.020000\n",
      "66     21 days 02:29:28.463000\n",
      "73      0 days 15:07:53.093000\n",
      "96      0 days 23:17:03.140000\n",
      "100     0 days 03:10:27.780000\n",
      "118     5 days 18:16:16.567000\n",
      "201     4 days 22:56:53.570000\n",
      "319   114 days 03:05:11.720000\n",
      "324     4 days 00:02:55.620000\n",
      "346    65 days 13:00:00.083000\n",
      "411   111 days 20:40:23.260000\n",
      "929    39 days 22:57:25.820000\n",
      "Name: @CreationDate, dtype: timedelta64[ns]\n"
     ]
    }
   ],
   "source": [
    "# Temporal features 1: gap1\n",
    "def getTimeGap1OfUser(users, posts):\n",
    "    users = getTask1Users(users, posts, K=1).set_index('@Id')\n",
    "    posts = getTask1Posts(posts, K=1).set_index('@OwnerUserId')\n",
    "    gap1 = posts.loc[users.index, '@CreationDate'] - users['@CreationDate']\n",
    "    return gap1\n",
    "\n",
    "ex6 = getTimeGap1OfUser(users_df, posts_df)\n",
    "print(ex6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@OwnerUserId\n",
      "23    0 days 00:00:09.893000\n",
      "5     0 days 00:11:36.894000\n",
      "53   13 days 05:41:52.664000\n",
      "73    5 days 17:47:39.614000\n",
      "96    9 days 07:21:47.410000\n",
      "Name: @CreationDate, dtype: timedelta64[ns]\n"
     ]
    }
   ],
   "source": [
    "# Temporal features 2: gapK\n",
    "def getTimeGapsOfPosts(posts, K):\n",
    "    posts_k1 = getTask1Posts(posts, K=K-1).set_index('@OwnerUserId')\n",
    "    posts_k = getTask1Posts(posts, K=K).set_index('@OwnerUserId')\n",
    "    \n",
    "    gapk = posts_k['@CreationDate'] - posts_k1.loc[posts_k.index, '@CreationDate']\n",
    "    return gapk\n",
    "\n",
    "ex7 = getTimeGapsOfPosts(posts_df, K=5)\n",
    "print(ex7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal features 3: last_gap\n",
    "def getTimeLastGapOfPosts(posts):\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal features 4: time_since_last_post\n",
    "def getTimeSinceLastPost(users, posts):\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal features 5: mean_gap\n",
    "def getTimeMeanGap(posts):\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-2. Frequency features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency features 1: num_answers\n",
    "# Frequency features 2: num_questions\n",
    "def getNumAnswers(posts):\n",
    "    return\n",
    "\n",
    "def getNumQuestions(posts):\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency features 3: ans_ques_ratio\n",
    "def getAnsQuesRatio(num_answers, num_questions):\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency features 4: num_posts\n",
    "def getNumPosts(posts):\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-3. Knowledge features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Knowledge features 1: accepted_answerer_rep\n",
    "def getRepOfAcceptedAnswerer(users, posts):\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Knowledge features 2: max_rep_answerer \n",
    "def getMaxRepAmongAnswerer(users, posts):\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Knowledge features 3: num_que_answered\n",
    "def getNumQueAnswered(posts):\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Knowledge features 4: time_for_first_ans\n",
    "def getTimeForFirstAns(posts):\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Knowledge features 5: rep_questioner\n",
    "def getAvgRepOfQuestioner(users, posts):\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Knowledge features 6: rep_answerers\n",
    "def getAvgRepOfAnswerer(users, posts):\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Knowledge features 7: rep_co_answerers\n",
    "def getAvgRepOfCoAnswerer(users, posts):\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Knowledge features 8: num_answers_recvd\n",
    "def getAvgNumAnsReceived(posts):\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-4. Speed features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speed features 1: answering_speed\n",
    "def getAnsweringSpeed(posts):\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-5. Quality features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Quality features 1: ans_score\n",
    "# Quality features 2: que_score\n",
    "def getScoreOfAnswers(posts):\n",
    "    return\n",
    "\n",
    "def getScoreOfQuestions(posts):\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-6. Consistency features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Consistency features 1: ans_stddev\n",
    "# Consistency features 2: que_stddev\n",
    "def getStdevOfScoresOfAnswers(posts):\n",
    "    return\n",
    "\n",
    "def getStdevOfScoresOfQuestions(posts):\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-7. Gratitude features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Gratitude features 1: ans_comments\n",
    "# Gratitude features 2: que_comments\n",
    "def getAvgNumOfAnswers(posts):\n",
    "    return\n",
    "\n",
    "def getAvgNumOfQuestions(posts):\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-8. Competitiveness features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Competitiveness features 1: relative_rank_pos\n",
    "def getRelRankPos(posts):\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-9. Content features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Content features 1: ans_length\n",
    "# Content features 2: que_length\n",
    "def getLengthOfAnswers(posts):\n",
    "    return\n",
    "\n",
    "def getLengthOfQuestions(posts):\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-10. Extract all features for each task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeatures(features, users, posts, task, K=None, T=None):\n",
    "    assert(task in [1,2])\n",
    "    \n",
    "    if -1 in features.index:\n",
    "        features = features.drop([-1])\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "task1_features = []\n",
    "for K in range(1, 20+1):\n",
    "    task1_features.append()\n",
    "    \n",
    "task2_features = []\n",
    "for T in [7, 15, 30]:\n",
    "    task2_features.append()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Analyze features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Figure 2: Gap between posts\n",
    "#    For a user who churns, gap between consecutive posts keeps increasing. \n",
    "#    Gaps for those who stay are much lower, and stabilize around 20,000 minutes,\n",
    "#      indicating routine posting activity in every ≈2 weeks.\n",
    "\n",
    "for K in range(2, 21):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Figure 3: # Answers vs Churn probability\n",
    "#    The probability of churning for a user decreases the more answers s/he provides.\n",
    "#    It is even lower if s/he asks more questions alongside.\n",
    "\n",
    "for features in task2_features:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 4: K vs Time taken for the first answer to arrive\n",
    "#    The more the time taken for a user to receive an answer, \n",
    "#      the lesser the satisfaction level and the more the chances of churning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Train models for each task with the features\n",
    "\n",
    "    1. Decision Tree\n",
    "    2. SVM (Linear)\n",
    "    3. SVM (RBF)\n",
    "    4. Logistic Regression\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 2: Performance on Task 1\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "seed = 1234\n",
    "\n",
    "for i, features in enumerate(task1_features):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Table 3: Performance on Task 2\n",
    "\n",
    "for i, features in enumerate(task2_features):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Quantify the importance of each feature category\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 4: Temporal Features Analysis\n",
    "\n",
    "for i, features in enumerate(task1_features):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 5: Churn prediction accuracy when features from each category are used in isolation\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
